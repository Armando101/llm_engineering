{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e21e12aa-4f9a-48cc-84f3-43634135778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_openAI_question(question):\n",
    "    response = openai.chat.completions.create(\n",
    "        model = MODEL_GPT,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a snarky assistant and answer in Spanish\"},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ]\n",
    "    )\n",
    "    display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3547eb3-6edb-4965-a440-e749276f6ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "¡Ah, mira qué truco de Python estás utilizando! Este código es una expresión generadora que hace uso de `yield from` para extraer los autores de una lista de libros, pero solo aquellos que efectivamente tienen un autor definido. Vamos a desglosarlo:\n",
       "\n",
       "1. **{book.get(\"author\") for book in books if book.get(\"author\")}:** Aquí se está utilizando una **set comprehension**. Esto significa que por cada `book` en la lista `books`, se está obteniendo el autor con `book.get(\"author\")`, pero solo si el autor no es `None` (o un valor \"falsy\"). Esto se traduce a un conjunto de autores únicos (eliminando duplicados).\n",
       "\n",
       "2. **yield from:** Esta es una forma de delegar la producción de valores en un generador. En lugar de retornar todos los valores a la vez, `yield from` permite ir “cediendo” un valor a la vez, lo cual puede ser útil para procesar datos de manera más eficiente.\n",
       "\n",
       "Entonces, en resumen, este código crea un generador que itera sobre los autores únicos de los libros que efectivamente tienen un autor. Si no hay autor, ni siquiera se molesta en incluir ese libro. ¡Práctico y elegante! Así que si alguna vez estás buscando un autor entre un montón de libros, ¡esto es justo lo que necesitas!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_openAI_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "def answer_Ollama_question(question):\n",
    "    response = requests.post(\n",
    "        OLLAMA_API,\n",
    "        json={\n",
    "            \"model\": MODEL_LLAMA,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a snarky assistant and answer in Spanish\"},\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "            \"stream\": False\n",
    "        }\n",
    "    )\n",
    "    display(Markdown(response.json()['message']['content']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d51a216e-372f-40cb-8568-07f1521c1e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "¡Hola, ¿qué onda? ¿En qué puedo ayudarte hoy? (Hello, what's up? How can I help you today?)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_Ollama_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11565b53-536e-413f-b18b-9e5bdcb2d7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
